{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bd8e35-3025-457e-b16c-9fa6947f6da5",
   "metadata": {},
   "source": [
    "# to do \n",
    "\n",
    "1) Read\n",
    "2) Tokenization\n",
    "3) Clean\n",
    "4) Count\n",
    "5) Answer: Return top 20 words that are repetead the most in the novel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af45922-3f34-4468-98bf-01a0298ed2e7",
   "metadata": {},
   "source": [
    "# 1) Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c341666-725d-4e2c-a033-d9d0793effcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('BookReading').getOrCreate()\n",
    "book = spark.read.text('dataset/pg1342.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32817eb2-6f3d-4595-9f7b-58cd4a2c10ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07aa7b28-4173-4ec1-a54f-b2f3614639ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94559a0b-ea05-4cae-b4a7-2349afda438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|The Project Guten...|\n",
      "|                    |\n",
      "|This ebook is for...|\n",
      "|most other parts ...|\n",
      "|whatsoever. You m...|\n",
      "|of the Project Gu...|\n",
      "|at www.gutenberg....|\n",
      "|you will have to ...|\n",
      "|before using this...|\n",
      "|                    |\n",
      "|Title: Pride and ...|\n",
      "|                    |\n",
      "| Author: Jane Austen|\n",
      "|                    |\n",
      "|Release date: Jun...|\n",
      "|                M...|\n",
      "|                    |\n",
      "|   Language: English|\n",
      "|                    |\n",
      "|Credits: Chuck Gr...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "book.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4174fc-143f-4991-8b37-973179b30bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|The Project Gutenberg eBook of Pride and Prejudice|\n",
      "|                                                  |\n",
      "|This ebook is for the use of anyone anywhere in...|\n",
      "|most other parts of the world at no cost and wi...|\n",
      "|whatsoever. You may copy it, give it away or re...|\n",
      "|of the Project Gutenberg License included with ...|\n",
      "|at www.gutenberg.org. If you are not located in...|\n",
      "|you will have to check the laws of the country ...|\n",
      "|                          before using this eBook.|\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "book.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c7721-05eb-4fb9-830b-f06d7661a64b",
   "metadata": {},
   "source": [
    "# 2) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e34c9e-b65c-4f63-a0fc-f5a1aa9c570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "lines = book.select(\n",
    "    split(col(\"value\"), \" \").alias(\"lines\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3563f56f-ef47-4e32-9fbc-52245fd7e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- lines: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd05368-8f6c-4aed-9fd4-e964be3c03c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               lines|\n",
      "+--------------------+\n",
      "|[The, Project, Gu...|\n",
      "|          [, , , , ]|\n",
      "|[This, ebook, is,...|\n",
      "|[most, other, par...|\n",
      "|[whatsoever., You...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "lines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f76108f-fcbf-415d-bb64-c159c6352ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      The|\n",
      "|  Project|\n",
      "|Gutenberg|\n",
      "|    eBook|\n",
      "|       of|\n",
      "+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# exploding the list into the seperate seperate tokens\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "words = lines.select(\n",
    "    explode(col(\"lines\")).alias(\"word\")\n",
    ")\n",
    "\n",
    "words.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b59b75-2730-47ee-8067-7b063d9b211d",
   "metadata": {},
   "source": [
    "# 3) Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f768af-de57-4223-9388-d7bf0065c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Changing Case and removing punctuation\n",
    "from pyspark.sql.functions import lower\n",
    "word_lower = words.select(\n",
    "    lower(col(\"word\")).alias(\"word_lower\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d905d58-896b-4161-b255-1593f46e28d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|word_lower|\n",
      "+----------+\n",
      "|       the|\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|     ebook|\n",
      "|        of|\n",
      "|     pride|\n",
      "|       and|\n",
      "| prejudice|\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|      this|\n",
      "|     ebook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "word_lower.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f8a607c-2fb2-48dc-bf9b-93fa8dcba7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|         |\n",
      "|         |\n",
      "|         |\n",
      "|         |\n",
      "|         |\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "## we are using regular expression functionality to only get us the words that are present in our dataset\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "word_clean = word_lower.select(\n",
    "    regexp_extract(col(\"word_lower\"), \"[a-z]*\", 0).alias(\"word\")\n",
    ")\n",
    "\n",
    "word_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2326b781-a0ab-4188-b9c3-639cacfc4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "|       in|\n",
      "|      the|\n",
      "|   united|\n",
      "+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "## fitering rows\n",
    "words_nonull = word_clean.where(col(\"word\") != \"\")\n",
    "words_nonull.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3815a2c-f66a-479b-86e1-cbb95d2ab66e",
   "metadata": {},
   "source": [
    "# 4) Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a881e8a-5603-40a9-b44f-aebf82c494f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupedData[grouping expressions: [word], value: [word: string], type: GroupBy]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = words_nonull.groupby(col(\"word\"))\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf8158bd-16fe-48d4-99ba-996576db034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|      online|    5|\n",
      "|       those|   65|\n",
      "|        some|  207|\n",
      "|     insipid|    2|\n",
      "|       still|   76|\n",
      "|         art|    7|\n",
      "|        hope|  126|\n",
      "|        earl|    3|\n",
      "|         few|   73|\n",
      "|   destitute|    2|\n",
      "|  palpitated|    1|\n",
      "|   connected|   15|\n",
      "|    cautious|    4|\n",
      "|   imitation|    1|\n",
      "|     solaced|    1|\n",
      "|      poetry|    2|\n",
      "|   arguments|    5|\n",
      "|premeditated|    1|\n",
      "|     elevate|    1|\n",
      "|      doubts|    2|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "results = words_nonull.groupby(col(\"word\")).count()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d581aac-a478-455a-b63b-2d985f04d788",
   "metadata": {},
   "source": [
    "# 5) Display the Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c91e93-ad63-4892-8094-0a1604a8272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Answer (ex top 10 words used in the book)\n",
    "results = results.orderBy(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6f84e3a-b78e-41df-b865-3637b29f0964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4803|\n",
      "|  to| 4374|\n",
      "|  of| 3951|\n",
      "| and| 3685|\n",
      "| her| 2254|\n",
      "|   a| 2063|\n",
      "|  in| 2024|\n",
      "| was| 1870|\n",
      "|   i| 1778|\n",
      "| she| 1703|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04384cf-d008-4cb2-b31d-3b45ccf507ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ea9c6-5b0d-4784-89c0-74bbccc96f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18404c1d-6117-49cb-81c5-64dab77a57a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pySpark myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
